# ‚ÄúVibe Coding‚Äù and the Myth of Agentic AI: A Rant (and a Reality Check)

## Intro

Imagine this: another day in your long career as a tech adjacent worker scrolling on LinkedIn...

*"Agentic AI" software this.*
*"Vibe Coding" that.*

All said from someone who most likely hasn't programmed a line of code in their life.

üòê What does it all mean?

## Definitions

**Agentic AI:** AI systems that can act autonomously and solve problems based on context and objectives.

**Vibe Coding:** A programming approach that utilizes AI tools to generate code from prompts rather than manual coding.

*Translation: make a vague wish to your AI genie and hope it compiles*

## What‚Äôs Happening

Listen... I am not the type of person to say that all LinkedIn is right now in the SDE space is a bunch of half-baked tech bros spamming the post button with their drivel about ‚ÄúüöÄ 10x Dev Productivity with Agentic AI.‚Äù

But I *am* saying it's starting to feel like it

However, I think it's time to address the issue at hand. The AI bubble might be growing more and more (with no end in sight), but soon it will pop, and the real developers will be here to pick up the pieces.

**The reality of the situation is this:**

We need to stop thinking of AI as a replacement to the work that's needed to create safe and effective software and start thinking of it as a tool.

‚úÖ Sure, agentic AI has its use cases.

Maybe it can help you write some boilerplate when you've got bigger things on your plate

Flag a pesky bug before it gets annoying.

But here‚Äôs the thing... just because it can do those things doesn‚Äôt mean we should forget how they work.

You still need to understand the scaffolding, not just copy and paste it.

## What They're Getting Wrong

We've all seen it: the moment someone shows a little competence, they suddenly start doing everything.

That's about where AI is right now.

It's a damn useful tool, no doubt. But somehow, we've made it the **project lead**, **QA engineer**, and the **CTO**. All without asking if it even knows what the product is. ü§∑

I'm not sure of the exact date, but somewhere in the past year or so we stopped treating AI as an assistant and started acting like it could replace the whole dev team. That's not innovation.

That's a **moral crisis wrapped in a buzzword.**

Think of the dot-com bubble...

The late 1990s was filled with <a href="https://www.goldmansachs.com/our-firm/history/moments/2000-dot-com-bubble" target="_blank">unseen growth</a> in information technology and telecom. The ease and cost of sending, storing, and reading information dipped. Fast. Personal computers were *the* thing and every industry they touched thought it had struck gold.

Sound familiar?

Startups with no revenue (or even real business models) got hyped into sky-high valuations... until the inevitable crash in the early 2000s.

<a href="https://finance.yahoo.com/news/dot-com-bubble-burst-25-100000416.html?guccounter=1&guce_referrer=aHR0cHM6Ly93d3cuZ29vZ2xlLmNvbS8&guce_referrer_sig=AQAAAL8I0R9fVc2mzuD3Q8_ykFKNd9FbXCAs613-1dbz2m8ltCAu_97TEGiZPtHJWVy99f1-0szQrNm_SFDtgc6c52ipLc8u-X2p7TcFipTeCuR4dCG0oZjsuZFw6QWnnOnGpLZkLvc_28hzcvGyWgGR-kY7jw9U0h5HLT32W1ZOnbRi" target="_blank">The NASDAQ lost over 75%</a> of its value and the entire stock market lost over 5 trillion almost overnight. üí•

Sure, that's just one crack in the crumbling wall of haphazard VC pitches, and honestly, it should make us pause.

The next few sections dig into what‚Äôs really at stake: <br>
üë©‚Äçüíª Jobs. <br>
‚öñÔ∏è Ethics. <br>
üåç The environment. <br>

It's not all bad, but we need to get real before the next bubble bursts.

## Real Implications: Job Loss and Ethical Concerns'

Let's start with a simple statistic:

<a href="https://www.pwc.es/es/ceos/2024/encuesta-mundial-ceos-2024.pdf" target="_blank">According to PwC‚Äôs 2024</a> Global CEO Survey, 1 in 4 CEOs expect to reduce headcount by at least 5% due to generative AI.

This picture isn't so simple. Many of these same CEOs plan on increasing hiring elsewhere, especially in tech.

It sounds balanced on paper, but in practice, it's just a reshuffling of the deck. ‚ô£Ô∏è

Roles that are cut often involve **entry-level, foundational workers.**

AKA, the first rung of the ladder. If we remove the bottom, how do we expect anyone to climb?

That isn't just a few roles at risk. <a href="https://www.goldmansachs.com/insights/articles/generative-ai-could-raise-global-gdp-by-7-percent" target="_blank">Goldman Sachs</a> estimated that the equivalent of **300 million full-time jobs** could be lost to automation created by generative AI.

Not every position is going to vanish overnight, but this projection signals a profound shift in the employment landscape.

I am not sure about you, but the ripple effects seem obvious to me:

- Internships are dwindling
- Junior roles are being cut
- Entry-level pathways are narrowing.

If we continue to treat AI as a wholesale replacement rather than a tool, we risk dismantling the very foundations that nurture and develop human talent.

### A Personal Reckoning

I‚Äôll be honest. As a software engineer, I‚Äôve written automation scripts, standalone tools, and web apps that streamlined workflows and cut out manual steps.

I‚Äôm sure some of that replaced someone‚Äôs job. It wasn‚Äôt malicious. It was a question of efficiency.

But efficiency without intention?

It's a quiet form of destruction.

These tools were never meant to erase the hard work of those before me.

They were meant to build new ladders! ü™ú

**Ladders that people could climb faster.** With more purpose. For people, not just profit.

### Final Thought for This Section

So to anyone reading this:

**Don‚Äôt let AI dictate your worth.**

Keep sharpening your craft.<br>
Be creative.<br>
Let your employer, your team, or even yourself know: <br>your value isn‚Äôt in what can be automated! It‚Äôs in the irreplaceable spark of what only *you* can build.

Because this isn‚Äôt just a fight over jobs.<br>
It‚Äôs a fight against the **slow erosion of the human spirit** and the earth we live in.

## Environmental Costs

While the human cost of AI adoption is becoming more visible, the environmental impact is still, *absolutely* ignored on a large scale.

Training and running large AI models requires an enormous amount of energy. These are often drawn from non-renewable sources. 

According to the <a href="https://www.iea.org/news/ai-is-set-to-drive-surging-electricity-demand-from-data-centres-while-offering-the-potential-to-transform-how-the-energy-sector-works" target="_blank">International Energy Agency</a>, AI-optimised data centers project to increase electric consumption to an astounding 900 terawatt-hours (TWh) of electricity by 2030. That's more than the **entire country of Japan üáØüáµ** uses in a year.

And don't get me started on the energy security concerns! Cyberattacks on utilities have tripled in the past four years, with AI increasing both frequency and sophistication.

That's just the energy too... These systems demand vast amounts of freshwater to cool the hardware. Upwards of <a href="https://news.lenovo.com/data-centers-worlds-ai-generators-water-usage/" target="_blank">*millions* of gallons</a> per year. **Water that is diverted from ecosystems and communities already under strain.**

There‚Äôs actually a name for all of this: the **Jevons Paradox**.

William Stanley Jevons wrote about it in *The Coal Question*. The idea is simple: as we become more efficient at using a resource, it becomes cheaper, and so we use more of it. Not less.

How does this relate to AI you might ask?

AI gets faster, cheaper, and easier to deploy... so we deploy it. Everywhere. The footprint doesn't shrink. **It grows.** ‚òùÔ∏è

So, while it's important to discuss how many jobs AI might automate. We are ignoring the **compounding ecological debt** that is being racked up to crank that hype machine until it sputters out.

This isn't about smarter code or cheaper labor anymore.

It's about the long-term cost of uncritical scale.

So how do we attempt to fix it?

## What We Should Actually Do

Let's be clear: this isn't an anti-AI rant. It's a **get-a-grip-on-reality** moment.

AI is a powerful tool! One of the most impactful in our lifetime. üìà

However, like any tool, it is only as good as how (and *why*) we use it. We shouldn't look at it as a cost-saving initiative to wipe developers from the map. It shouldn't be used to pitch a miracle fix for bloated workflows or weak leadership. And it *damn sure* shouldn't be an excuse to gut mentorship programs and junior roles under the guise of "efficiency."

We don't need another agent writing boilerplate code, guys. We need more engineers **(ESPECIALLY YOU, JUNIORS)** who understand *why* that boilerplate exists. 

We need leaders to invest in **good practices** not just give warnings about AI. All organizations need to treat AI like a scalpel, not a bulldozer.

My take on a responsible path forward? ‚è© I think it looks like this:

- Keep AI in the loop, but **humans should be in charge.**
- Use AI to accelerate learning, but it should be a helper **not replace the process.**
- Push for tools that augment creativity, but not ones that **erase our crafts.**
- Find regular periods to step away from AI, **not find more ways to include it.**

If we don't set the tone for how AI fits into SDE, someone else will. From my perspective, they won't have the same respect for ethics, the energy, or the people that actually hold the *passion* of this industry together.

## Final Thoughts

I feel like this sounds like a call to revolution, but it's not. We are just at a crossroads!

AI is not coal, and it's not steam. It's not here to replace us, but it is here to test us. To see if we're going to chase the hype the same way we did during the 90s until the power grid cracks and the junior pipeline dries up, or if we're going to use this moment to actually build better systems... Both technical *and* human.

The Jevons Paradox still looms, sure. I don't think the answer is to resist the tools, but to create with more intention. More care. More damn responsibility.

Don't erase the craft. Protect it. Evolve it. And make damn sure it stays human.
